{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='bar_title'></div>\n",
    "\n",
    "*Simulation for Decision Making (S4DM)*\n",
    "\n",
    "# Assignment 6: Output Analysis (Single Model)\n",
    "\n",
    "Summer Semester 24\n",
    "\n",
    "\n",
    "Gunther Gust & Ignacio Ubeda <br>\n",
    "Chair for Enterprise AI <br>\n",
    "Data Driven Decisions Group <br>\n",
    "Center for Artificial Intelligence and Data Science (CAIDAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/d3.png\" style=\"width:20%; float:left;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/CAIDASlogo.png\" style=\"width:20%; float:left;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "\n",
    "* Model Validation\n",
    "* Output Analysis (Single Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car wash example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventLogger:\n",
    "    def __init__(self):\n",
    "        self.logs = []\n",
    "        self.replication = None #replication number\n",
    "        self.seed = None #seed used for the replication\n",
    "    \n",
    "    def set_replication_info(self, replication, seed):\n",
    "        self.replication = replication\n",
    "        self.seed = seed\n",
    "\n",
    "    def log_car_arrival(self, entity, time):\n",
    "        self.logs.append({'replication_id': self.replication, 'seed': self.seed, #replication info\n",
    "                          'event_time': time, 'event_name': 'car_arrival', 'event_key': entity #simulation info\n",
    "                          })\n",
    "    \n",
    "    def log_car_wash_request(self, entity, time):\n",
    "        self.logs.append({'replication_id': self.replication, 'seed': self.seed, #replication info\n",
    "                          'event_time': time, 'event_name': 'car_wash_request', 'event_key': entity #simulation info\n",
    "                          })\n",
    "\n",
    "    def log_car_departure(self, entity, time):\n",
    "        self.logs.append({'replication_id': self.replication, 'seed': self.seed, #replication info\n",
    "                          'event_time': time, 'event_name': 'car_departure', 'event_key': entity #simulation info\n",
    "                          })\n",
    "\n",
    "    def get_logs_df(self):\n",
    "        return pd.DataFrame(self.logs)\n",
    "    \n",
    "    def dump_logs_df(self, filepath=None):\n",
    "        if filepath is None: \n",
    "            filepath = \"logs.csv\"\n",
    "\n",
    "        self.get_logs_df().to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Carwash:\n",
    "    def __init__(self, env, num_machines, logger):\n",
    "        self.env = env\n",
    "        self.machine = simpy.Resource(env, num_machines)\n",
    "        self.logger = logger\n",
    "\n",
    "    def wash(self):\n",
    "        yield self.env.timeout(np.random.exponential(1/0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car:\n",
    "    def __init__(self, env, name, carwash, logger):\n",
    "        self.env = env\n",
    "        self.name = name\n",
    "        self.logger = logger\n",
    "\n",
    "        self.env.process(self.run(carwash))\n",
    "\n",
    "    def run(self, carwash):\n",
    "        \n",
    "        # Log the arrival\n",
    "        self.logger.log_car_arrival(self.name, self.env.now)\n",
    "        with carwash.machine.request() as request:\n",
    "            yield request\n",
    "\n",
    "            # Log the request for car wash\n",
    "            self.logger.log_car_wash_request(self.name, self.env.now)\n",
    "            yield self.env.process(carwash.wash())\n",
    "\n",
    "            #Log the departure\n",
    "            self.logger.log_car_departure(self.name, self.env.now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_generator(env, carwash, logger):\n",
    "    car_count = 0\n",
    "\n",
    "    # Create cars while the simulation is running\n",
    "    while True:\n",
    "        yield env.timeout(np.random.exponential(1/0.5))\n",
    "        Car(env, f'Car {car_count}', carwash, logger)\n",
    "        car_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simulation (now, for multiple replications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "NUM_MACHINES = 2    # Number of machines in the carwash\n",
    "SIM_TIME = 8*60       # Simulation time in minutes\n",
    "N_REPLICATIONS = 20 # Number of Replications\n",
    "\n",
    "# Setup and start the simulation\n",
    "print('Running Simulation...')\n",
    "\n",
    "#define logger (same for all replications)\n",
    "logger = EventLogger()\n",
    "\n",
    "#Compute a pool of seeds that is larger than the number of replications\n",
    "safe_factor = 10\n",
    "pool_of_seeds = range(1, N_REPLICATIONS * safe_factor)\n",
    "\n",
    "#get a list of seeds of length: N_REPLICATIONS from a pool of seeds. \n",
    "#We set replace=False to ensure that we don't reuse the same seed twice.\n",
    "list_of_seeds = np.random.choice(pool_of_seeds, size=N_REPLICATIONS, replace=False)\n",
    "\n",
    "for i, seed in enumerate(list_of_seeds):\n",
    "    print(f'Running Replication {i} with seed: {seed} ...')\n",
    "\n",
    "    #set random seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #set replication id and random seed\n",
    "    logger.set_replication_info(i, seed)\n",
    "\n",
    "    # Create an environment and start the setup process\n",
    "    env = simpy.Environment()\n",
    "\n",
    "    #define resources\n",
    "    carwash = Carwash(env, NUM_MACHINES, logger)\n",
    "\n",
    "    #define processes\n",
    "    env.process(car_generator(env, carwash, logger))\n",
    "\n",
    "    # Execute\n",
    "    env.run(until=SIM_TIME)\n",
    "\n",
    "print('... Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = logger.get_logs_df()\n",
    "\n",
    "events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise / Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks are independently of each other.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to validate our model. We've measured the actual average waiting time (2.8 mins) and would like to compare it with the output of our simulation model. \n",
    "\n",
    "-----\n",
    "\n",
    "**Task 1.1: Create a dataframe `results_df` that contains the waiting time for every entity (car) for every replication. Recall that the waiting time is the timespan between the \"*car_wash_request*\" and \"*car_arrival*\" event. For computing this you can choose whatever approach you want. Check Hint 1 for a suggestion.**\n",
    "\n",
    "**Task 1.2: Once you have `results_df`, compute the average waiting time for every replication. For computing this you can choose whatever approach you want. Check Hint 2 for a suggestion.**\n",
    "\n",
    "After Task 1.2 you should have a table that looks like this (not same values, but structure):\n",
    "\n",
    "<img src=\"images/assignment6_validation_lecture.png\" style=\"width:30%\" />\n",
    "\n",
    "Where you have an aggregated metric for every replication (in the lecture example, $Y_2$). In our case, the table should have (at least) 2 columns: a replication id and the average waiting time for that replication.\n",
    "\n",
    "**Task 1.3: Compute a confidence interval for the average waiting time (accross replications). Use the following formula (Lecture 8, slide 30):**\n",
    "\n",
    "<img src=\"images/assignment6_ciformula_lecture.png\" style=\"width:20%\" />\n",
    "\n",
    "**For gettint the t value, you may want to use `stats.t.ppf` from `scipy`. Check the [reference](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html) for more details.**\n",
    "\n",
    "**Task 1.4: You've measure the actual average wating time (2.8 mins). Create an hypothesis test, interpret it, and check if your model is valid. For computing this you can choose whatever approach you want. Check Hint 3 for a suggestion.**\n",
    "\n",
    "-----\n",
    "\n",
    "**Hint 1:** `events_df` is in [long format](https://www.statology.org/long-vs-wide-data/). To compute the waiting time would be easier if its wide. To reshape from long to wide you could use the function: [`pd.pivot_table`](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html)\n",
    "\n",
    "**Hint 2:** For aggregating a value (column `v`) with a function `f`  for every group (column `g`) of a DataFrame `df`. You can use the following syntax: `df.groupby('g').agg({'v': [f]})`. Check the [reference](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html) for more details.\n",
    "\n",
    "**Hint 3:** `scipy` has a working implementation of a t-test: `stats.ttest_1samp`. Check the [reference](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html) for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#long to wide format (Hint 1)\n",
    "results_df = #your code here\n",
    "\n",
    "#compute waiting time\n",
    "results_df['waiting_time'] = #your code here\n",
    "\n",
    "print(results_df.columns)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you have followed Hint 1: Leave this code unchanged. If not, you can remove it.\n",
    "\n",
    "#Note the \"\\\"\" character is used to split a long line of code into multiple lines\n",
    "#We can therefore \"chain\" multiple operations together, which makes the code more readable\n",
    "\n",
    "#1st: filter for replication 0\n",
    "#2nd: sort by car arrival time (ascending)\n",
    "#3rd: show the first 10 rows\n",
    "\n",
    "results_df\\\n",
    "    .loc[results_df['replication_id'] == 0]\\\n",
    "    .sort_values(by='car_arrival', ascending=True)\\\n",
    "    .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the average waiting time for every replication\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#significance level\n",
    "alpha = 0.05\n",
    "\n",
    "#compute mean, std and sample size\n",
    "sample_size = #your code here\n",
    "sample_mean = #your code here\n",
    "sample_std = #your code here\n",
    "\n",
    "print(f\"sample mean: {sample_mean}\")\n",
    "print(f\"sample std: {sample_std}\")\n",
    "\n",
    "#Calculate t confidence interval\n",
    "\n",
    "# Calculate the t-value for a 95% confidence interval (two-sided)\n",
    "t_value = #your code here\n",
    "\n",
    "# Calculate the half-width of the confidence interval\n",
    "ci_halfwidth = #your code here\n",
    "\n",
    "#calculate the lower and upper bounds of the confidence interval\n",
    "ci_lb = #your code here\n",
    "ci_ub = #your code here\n",
    "\n",
    "print(f\"t confidence int: [{ci_lb}, {ci_ub}]\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform  t-test\n",
    "#your code here\n",
    "\n",
    "\n",
    "#interpret the test\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "\n",
    "- Is the simulation model valid?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer in this markdown chunk:**\n",
    "\n",
    "- *Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Number of Replications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have run 100 replications of our simulation model and now we'd like to compute how many replications do we need to ensure a specific margin of error in our output measurement.\n",
    "\n",
    "-----\n",
    "\n",
    "**Task 2.1: With the available DataFrame (`replication_results`) compute the number of replications (R) needed to have an error $\\epsilon = 0.2$ with a significance level $\\alpha = 0.05.$ Use the following formula (Lecture 9, slide 27):**\n",
    "\n",
    "<img src=\"images/assignment6_nreplications_lecture.png\" style=\"width:20%\" />\n",
    "\n",
    "**For gettint the t value, you may want to use `stats.t.ppf` from `scipy`. Check the [reference](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html) for more details.**\n",
    "\n",
    "**Task 2.2: Pack your implementation in a function `sample_size_calculator` and use it to answer how the sample size changes varying $\\epsilon$ and $\\alpha$**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replication_results = pd.read_csv('replication_results.csv')\n",
    "\n",
    "print(replication_results.shape)\n",
    "replication_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.2\n",
    "alpha = 0.05\n",
    "\n",
    "R0 = #your code here (initial number of replications)\n",
    "t_value = #your code here\n",
    "s0 = #your code here (initial standard deviation)\n",
    "\n",
    "R = #your code here\n",
    "\n",
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "\n",
    "- How many replications are needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer in this markdown chunk:**\n",
    "\n",
    "- *Your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_size_calculator(alpha, epsilon, s0, R0):\n",
    "    t_value = #your code here\n",
    "    R = #your code here\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave this code unchanged\n",
    "\n",
    "#define epsilon and alpha ranges\n",
    "epsilon_values = np.arange(0.0, 1.0, 0.05)\n",
    "alpha_values = np.arange(0.0, 1.0, 0.05)\n",
    "\n",
    "data = []\n",
    "\n",
    "#iterate over epsilon and alpha values\n",
    "for epsilon in epsilon_values:\n",
    "    for alpha in alpha_values:\n",
    "        \n",
    "        #compute sample size\n",
    "        try:\n",
    "            R = sample_size_calculator(alpha, epsilon, s0, R0)\n",
    "        except OverflowError:\n",
    "            R = np.nan\n",
    "\n",
    "        #append results to data\n",
    "        data.append({'alpha': round(alpha, 2), 'epsilon': round(epsilon, 2), 'sample_size': R})\n",
    "        \n",
    "#convert data to DataFrame and pivot\n",
    "df = pd.DataFrame(data)\n",
    "df = df.pivot(index=\"alpha\", columns=\"epsilon\", values=\"sample_size\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave this code unchanged\n",
    "sns.heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "\n",
    "1. How does the number of replications (R) change when changing $\\epsilon$?\n",
    "1. How does the number of replications (R) change when changing $\\alpha$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer in this markdown chunk:**\n",
    "\n",
    "1. *Your answer here*\n",
    "1. *Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Quantile Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to compute a confidence interval for a a specific quantile of the average waiting time.\n",
    "\n",
    "-----\n",
    "\n",
    "**Task 3.1: Sort the the available DataFrame (`replication_results`) by the `waiting_time_mean` ascending. Create a `rank` column to get the position of the rows of the sorted DataFrame.**\n",
    "\n",
    "**Task 3.2: Compute the quantile (lower and upper) bounds for the quantile $p=0.8$ with a significance level $\\alpha = 0.05$. Use the following formula (Lecture 9, slide 29):**\n",
    "\n",
    "<img src=\"images/assignment6_quantilebounds_lecture.png\" style=\"width:20%\" />\n",
    "\n",
    "**For gettint the z value, you may want to use `stats.norm.ppf` from `scipy`. Check the [reference](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html) for more details.**\n",
    "\n",
    "**Task 3.3: Compute the point estimate and the bounds of the confidence interval with the indexes of the sorted DataFrame (i.e. the `rank` column). Check the example on Lecture 9, slide 30.**\n",
    "\n",
    "**Task 3.4: Finally, we'll use a another approach using the `.quantile()` function. Check the [reference](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html) for more details and compare it with the result of Task 3.3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv\n",
    "replication_results = pd.read_csv('replication_results.csv')\n",
    "print(replication_results.shape)\n",
    "\n",
    "#show the first 5 rows\n",
    "replication_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show last 5 rows\n",
    "replication_results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histogram\n",
    "sns.histplot(replication_results['waiting_time_mean'], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by waiting time mean (ascending)\n",
    "replication_results = #your code here\n",
    "\n",
    "#create rank column\n",
    "replication_results['rank'] = #your code here\n",
    "\n",
    "replication_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "quantile = 0.8\n",
    "sample_size = #your code here\n",
    "\n",
    "#compute z-value\n",
    "z_value = #your code here\n",
    "\n",
    "#compute quantile lower and upper bounds\n",
    "quantile_lb = #your code here\n",
    "quantile_ub = #your code here\n",
    "\n",
    "print(quantile_lb, quantile_ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the row index of the quantile (lb, ub, and center)\n",
    "quantile_lb_index = #your code here\n",
    "quantile_index = #your code here\n",
    "quantile_ub_index = #your code here\n",
    "\n",
    "#compute the point estimate\n",
    "point_estimate = #your code here\n",
    "\n",
    "#compute the confidence interval\n",
    "ci_lb = #your code here\n",
    "ci_ub = #your code here\n",
    "\n",
    "print(f\"The point estimate is: {point_estimate}\")\n",
    "print(f\"The {100*(1-alpha)}% CI is [{ci_lb}, {ci_ub}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the point estimate (now with the quantile function)\n",
    "point_estimate_quantfunc = #your code here\n",
    "\n",
    "#compute the confidence interval (now with the quantile function)\n",
    "ci_lb_quantfunc = #your code here\n",
    "ci_ub_quantfunc = #your code here\n",
    "\n",
    "print(f\"The point estimate (quantile function) is: {point_estimate_quantfunc}\")\n",
    "print(f\"The {100*(1-alpha)}% CI (quantile function) is [{ci_lb_quantfunc}, {ci_ub_quantfunc}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "\n",
    "- What is the difference in values of both approaches? which one is better to use in which scenario?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer in this markdown chunk:**\n",
    "\n",
    "- *Your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Replication Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming now that our carwash runs 24/7, we're interested in implementing the replication method and differentiating between the transient vs the steady-state phase. \n",
    "\n",
    "For this task we'll change the metric to the queue length and we'll monitor it periodically to ensure we have exactly the same sampling frequency among different replications.\n",
    "\n",
    "-----\n",
    "\n",
    "**Task 4.1: Create a new method in the `EventLogger_Task4` to log the queue length. You should log (at least) the replication id, the time and the value of the queue length.**\n",
    "\n",
    "**Task 4.2: Create a new process in the `Carwash_Task4` to monitor the queue length every 5 minutes. Note that this is a \"ficticious\" process that does not interact with the entity. The solely purpose is to monitor (and log) our variable of interest (queue length in this case).**\n",
    "\n",
    "**Task 4.3: With this new changes, run your simulation replications (we provide this code for you) and filter the `events_t4_df` to get only the events related to the queue length.**\n",
    "\n",
    "**Task 4.4: Plot the queue length over time. Note that since we have multiple records for the same time step (because we have one for each replication). The plot will aggregate the `y` value with a confidence interval around the mean.**\n",
    "\n",
    "**Task 4.5: Determine a `T1` (the point in time where you should \"cut\" between transient and steady-state phase)**\n",
    "\n",
    "**Task 4.6: Finally, compute the average queue length with and without the transient phase and compare your results. Note that you'll have to compute first the average queue length within replications and then, the average of this value accross replications.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventLogger_Task4:\n",
    "    def __init__(self):\n",
    "        self.logs = []\n",
    "        self.replication = None #replication number\n",
    "        self.seed = None #seed used for the replication\n",
    "    \n",
    "    def set_replication_info(self, replication, seed):\n",
    "        self.replication = replication\n",
    "        self.seed = seed\n",
    "\n",
    "    def log_car_arrival(self, entity, time):\n",
    "        self.logs.append({'replication_id': self.replication, 'seed': self.seed, #replication info\n",
    "                          'event_time': time, 'event_name': 'car_arrival', 'event_key': entity #simulation info\n",
    "                          })\n",
    "    \n",
    "    def log_car_wash_request(self, entity, time):\n",
    "        self.logs.append({'replication_id': self.replication, 'seed': self.seed, #replication info\n",
    "                          'event_time': time, 'event_name': 'car_wash_request', 'event_key': entity #simulation info\n",
    "                          })\n",
    "\n",
    "    def log_car_departure(self, entity, time):\n",
    "        self.logs.append({'replication_id': self.replication, 'seed': self.seed, #replication info\n",
    "                          'event_time': time, 'event_name': 'car_departure', 'event_key': entity #simulation info\n",
    "                          })\n",
    "\n",
    "    #add a new method to log the queue length    \n",
    "    #your code here\n",
    "    \n",
    "\n",
    "    def get_logs_df(self):\n",
    "        return pd.DataFrame(self.logs)\n",
    "    \n",
    "    def dump_logs_df(self, filepath=None):\n",
    "        if filepath is None: \n",
    "            filepath = \"logs.csv\"\n",
    "\n",
    "        self.get_logs_df().to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Carwash_Task4:\n",
    "    def __init__(self, env, num_machines, logger):\n",
    "        self.env = env\n",
    "        self.machine = simpy.Resource(env, num_machines)\n",
    "        self.logger = logger\n",
    "\n",
    "        self.env.process(self.monitor_queue_length()) #NEW - start the monitor process\n",
    "\n",
    "    def wash(self):\n",
    "        yield self.env.timeout(np.random.exponential(1/0.3))\n",
    "    \n",
    "    #create a new process to monitor the queue length every 5 minutes\n",
    "    #your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave this code unchanged\n",
    "\n",
    "# parameters\n",
    "NUM_MACHINES = 2       # Number of machines in the carwash\n",
    "SIM_TIME = 7*24*60      # Simulation time in minutes\n",
    "N_REPLICATIONS = 30     # Number of Replications\n",
    "\n",
    "# Setup and start the simulation\n",
    "print('Running Simulation...')\n",
    "\n",
    "#define logger (same for all replications)\n",
    "logger_t4 = EventLogger_Task4()\n",
    "\n",
    "#Compute a pool of seeds that is larger than the number of replications\n",
    "safe_factor = 10\n",
    "pool_of_seeds = range(1, N_REPLICATIONS * safe_factor)\n",
    "\n",
    "#get a list of seeds of length: N_REPLICATIONS from a pool of seeds. \n",
    "#We set replace=False to ensure that we don't reuse the same seed twice.\n",
    "list_of_seeds = np.random.choice(pool_of_seeds, size=N_REPLICATIONS, replace=False)\n",
    "\n",
    "for i, seed in enumerate(list_of_seeds):\n",
    "    print(f'Running Replication {i} with seed: {seed} ...')\n",
    "\n",
    "    #set random seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #set replication id and random seed\n",
    "    logger_t4.set_replication_info(i, seed)\n",
    "\n",
    "    # Create an environment and start the setup process\n",
    "    env_t4 = simpy.Environment()\n",
    "\n",
    "    #define resources\n",
    "    carwash_t4 = Carwash_Task4(env_t4, NUM_MACHINES, logger_t4)\n",
    "\n",
    "    #define processes\n",
    "    #we use the same car_generator and Car class because has not changed\n",
    "    env_t4.process(car_generator(env_t4, carwash_t4, logger_t4))\n",
    "\n",
    "    # Execute\n",
    "    env_t4.run(until=SIM_TIME)\n",
    "\n",
    "print('... Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave this code unchanged\n",
    "events_t4_df = logger_t4.get_logs_df()\n",
    "\n",
    "print(events_t4_df.shape)\n",
    "events_t4_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only the queue_monitor events\n",
    "queue_data = #your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set figure size\n",
    "f, ax = plt.subplots(1, figsize=(20, 7))\n",
    "\n",
    "#plot the queue length over time\n",
    "sns.lineplot(data=#your code here\n",
    "             x=#your code here\n",
    "             y=#your code here \n",
    "             ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the time point T1\n",
    "T1 = #your code here\n",
    "\n",
    "#set figure size\n",
    "f, ax = plt.subplots(1, figsize=(20, 7))\n",
    "\n",
    "#plot the queue length over time\n",
    "sns.lineplot(data=#your code here\n",
    "             x=#your code here\n",
    "             y=#your code here\n",
    "             ax=ax)\n",
    "plt.axvline(x=T1, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check rule of thumb: TE > 10*T1\n",
    "TE = (SIM_TIME-T1)\n",
    "print(TE > 10*T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the point estimate of the mean queue length within replications\n",
    "#your code here\n",
    "\n",
    "#Compute the point estimate of the mean queue length accross replications\n",
    "point_estimator_with_transient = #your code here\n",
    "point_estimator_with_transient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the point estimate of the mean queue length within replications but deleting the first T1 minutes\n",
    "#your code here\n",
    "\n",
    "#Compute the point estimate of the mean queue length accross replications but deleting the first T1 minutes\n",
    "point_estimator_without_transient = #your code here\n",
    "point_estimator_without_transient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the point estimates\n",
    "point_estimator_with_transient - point_estimator_without_transient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "\n",
    "- What is the difference in the point estimates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer in this markdown chunk:**\n",
    "\n",
    "- *Your answer here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
